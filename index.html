<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Yunwoo Lee | Academic Homepage</title>
    
    <link rel="icon" type="image/png" href="assets/favicon.png">

    <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">
    
    <style>
        /* [1. 기본 설정: 폰트 및 전체 레이아웃] */
        body {
            /* Lato 폰트 적용 */
            font-family: 'Lato', -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            /* 배경색: 따뜻한 베이지(#fbf7f0) */
            background-color: #fbf7f0;
            color: #333;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            font-size: 15px;
        }

        /* 링크 스타일 */
        a {
            color: #0066cc;
            text-decoration: none;
            transition: color 0.2s, text-decoration 0.2s;
        }

        a:hover {
            color: #003399;
            text-decoration: underline;
        }

        /* [2. 메인 컨테이너] */
        .container {
            max-width: 960px;
            margin: 0 auto;
            padding: 40px 20px;
            display: flex;
            gap: 50px;
        }

        /* [3. 왼쪽 프로필 섹션] */
        .profile-section {
            flex: 0 0 250px;
            text-align: left;
        }

        /* 프로필 이미지: 둥근 직사각형 */
        .profile-img {
            width: 100%;
            max-width: 220px;
            height: auto; /* 비율 유지 */
            object-fit: cover;
            border-radius: 12px; /* 모서리 둥글게 */
            margin-bottom: 20px;
            box-shadow: 0 4px 10px rgba(0,0,0,0.1);
            background-color: #e8e4dc;
        }

        .name {
            font-size: 1.8rem;
            font-weight: 700;
            margin-bottom: 5px;
            color: #111;
        }

        .affiliation {
            font-size: 0.95rem;
            color: #666;
            margin-bottom: 20px;
        }

        .contact-links a {
            display: block;
            margin-bottom: 5px;
            font-size: 0.9rem;
        }

        /* [4. 오른쪽 메인 콘텐츠 섹션] */
        .main-content {
            flex: 1;
        }

        section {
            margin-bottom: 50px;
        }

        h2 {
            font-size: 1.5rem;
            border-bottom: 2px solid #e0ded5;
            padding-bottom: 10px;
            margin-bottom: 20px;
            color: #111;
            font-weight: 700;
        }

        /* About Me 스타일 */
        .about-text {
            margin-bottom: 15px;
        }

        /* [5. 뉴스 리스트 스타일] */
        .news-list {
            list-style: none;
            padding: 0;
        }

        .news-list li {
            margin-bottom: 10px;
            font-size: 0.95rem;
        }

        .news-date {
            font-weight: bold;
            color: #444;
            margin-right: 10px;
        }

        /* [6. 경력 아이템 스타일] */
        .experience-item {
            margin-bottom: 30px;
        }

        .experience-title {
            font-size: 1.1rem;
            font-weight: 700;
            color: #111;
            margin-bottom: 4px;
        }

        .experience-meta {
            font-size: 0.9rem;
            color: #555;
            margin-bottom: 8px;
            font-style: italic;
        }

        .experience-desc {
            font-size: 0.95rem;
            color: #444;
            margin-bottom: 8px;
        }

        /* 기술 태그 스타일 */
        .tech-tag {
            display: inline-block;
            background-color: #ffffff;
            border: 1px solid #e0ded5;
            color: #555;
            font-size: 0.8rem;
            padding: 3px 8px;
            border-radius: 4px;
            margin-right: 5px;
            margin-top: 5px;
            font-weight: 400;
        }

        /* [7. 모바일 반응형] */
        @media (max-width: 768px) {
            .container {
                flex-direction: column;
                gap: 30px;
            }

            .profile-section {
                text-align: center;
                border-bottom: 1px solid #e0ded5;
                padding-bottom: 20px;
            }
            
            .profile-img {
                margin: 0 auto 20px auto;
            }

            .contact-links a {
                display: inline-block;
                margin: 0 10px;
                padding: 5px;
            }
        }
    </style>
</head>
<body>

    <div class="container">
        
        <aside class="profile-section">
            <img src="assets/profile.jpg" alt="Yunwoo Lee" class="profile-img">
            
            <div class="name">Yunwoo Lee</div>
            <div class="affiliation">
                M.S. Student in Computational Linguistics<br>
                University of Washington<br>
                Seattle, WA
            </div>
            
            <div class="contact-links">
                <a href="mailto:yunu919@uw.edu">yunu919@uw.edu</a>
                <a href="https://www.linkedin.com/in/yunu919/" target="_blank">LinkedIn</a>
                <a href="https://github.com/yunlee919" target="_blank">GitHub</a>
                <a href="assets/YunwooLee_CV.pdf" target="_blank">Curriculum Vitae (PDF)</a>
            </div>
        </aside>

        <main class="main-content">
            
            <section id="about">
                <h2>About Me</h2>
                <p class="about-text">
                    I’m a Master’s student in Computational Linguistics at the 
                    <a href="https://www.washington.edu/" target="_blank">University of Washington</a> in Seattle. 
                    I’m broadly interested in computational linguistics and NLP, especially in how linguistic structure and meaning can be modeled and used to build better language technologies.
                </p>
                <p class="about-text">
                    More recently, I’ve become particularly interested in trustworthy LLMs: how we can evaluate and improve models’ reliability in real-world settings, with a focus on hallucination, fairness, and socio-cultural bias.
                </p>
                <p class="about-text">
                    I previously worked at 
                    <a href="https://www.keti.re.kr/eng/main/main.php" target="_blank">Korea Electronics Technology Institute(KETI)</a>, 
                    <a href="https://nc-ai.com/en" target="_blank">NCSOFT</a>, and 
                    <a href="https://www.sktelecom.com/index_en.html" target="_blank">SK Telecom</a>. 
                    Those experiences made me care about how language models behave in the real world, not just how accurate they are, but how reliable and fair they can be.
                </p>
                <p class="about-text">
                    I hold a B.A. in Linguistics & Cognitive Science and a double major in Language Science in Artificial Intelligence from 
                    <a href="https://www.hufs.ac.kr/hufs/index.do" target="_blank">Hankuk University of Foreign Studies</a>, 
                    where I was advised by 
                    <a href="http://dicora.kr/p033-local-grammar-based-text-labeling/?ckattempt=1" target="_blank">Prof. Jeesun Nam</a>.
                </p>
            </section>

            <section id="news">
                <h2>News</h2>
                <ul class="news-list">
                    <li><span class="news-date">Sep 2025</span> Started M.S. in Computational Linguistics at <strong>University of Washington</strong>.</li>
                </ul>
            </section>

            <section id="work">
                <h2>Work Experience</h2>
                
                <div class="experience-item">
                    <div class="experience-title">
                        Trustworthiness Benchmarks for Korean LLMs
                    </div>
                    <div class="experience-meta">
                        Researcher @ <a href="https://www.keti.re.kr/eng/main/main.php" target="_blank">KETI</a> | Sep 2024 - Jun 2025
                    </div>
                    <div class="experience-desc">
                        <p>
                            I worked on building evaluation resources for Korean LLMs with an emphasis on linguistically grounded reliability:
                            how models maintain grounded claims, interpret indirect meaning, and respond appropriately under pragmatic pressure.
                            Rather than scoring only “correct/incorrect,” I focused on identifying discourse-level failure patterns and the linguistic triggers behind them.
                        </p>
                        <ul style="margin: 8px 0 0 18px;">
                            <li>Designed prompt suites and rubric-based evaluations for groundedness/hallucination, with failure-mode categories tied to discourse phenomena (e.g., attribution, consistency, hedging).</li>
                            <li>Developed annotation guidelines to assess socio-cultural bias and pragmatic harm, emphasizing appropriateness in Korean register and stance.</li>
                            <li>Validated a Korean multimodal dialogue dataset by aligning utterance-level pragmatic functions (e.g., agreement, refusal, hesitation) with nonverbal cue labels.</li>
                        </ul>
                        <p style="margin-top: 10px;">
                            <em>Key insight:</em> many reliability issues are not isolated “wrong facts,” but emerge from how meaning is constructed across turns (implicature, underspecification, and discourse coherence).
                        </p>
                    </div>
                    <div>
                        <span class="tech-tag">Discourse Evaluation</span>
                        <span class="tech-tag">Pragmatics</span>
                        <span class="tech-tag">Failure-Mode Analysis</span>
                    </div>
                </div>

                <div class="experience-item">
                    <div class="experience-title">
                        AI Red Teaming & Safety Protocols
                    </div>
                    <div class="experience-meta">
                        Language AI Researcher @ <a href="https://nc-ai.com/en" target="_blank">NCSOFT</a> | Mar 2024 - Sep 2024
                    </div>
                    <div class="experience-desc">
                        <p>
                            I supported safety-focused evaluation for conversational AI by building test cases that treat risk as a linguistic and interactional phenomenon.
                            In addition to single-turn risk detection, I evaluated context-aware harmfulness in multi-turn settings where intent becomes clearer through discourse trajectories.
                        </p>
                        <ul style="margin: 8px 0 0 18px;">
                            <li>Created semantics-informed risk probes for single-turn inputs, including cases where meaning depends on polysemy or indirect phrasing.</li>
                            <li>Developed multi-turn scenarios to capture escalation patterns (justification → concretization → actionable request) and measured how risk accumulates over dialogue context.</li>
                            <li>Analyzed evasion behaviors after refusals (repair/paraphrase, euphemisms), and incorporated these patterns into testing protocols.</li>
                        </ul>
                        <p style="margin-top: 10px;">
                            <em>Key insight:</em> risk is often discourse-driven—what looks harmless in isolation can become unsafe when reference resolution, implicature, and turn-by-turn intent shifts are taken into account.
                        </p>
                    </div>
                    <div>
                        <span class="tech-tag">Semantic Risk Signals</span>
                        <span class="tech-tag">Context-Aware Safety</span>
                        <span class="tech-tag">Conversation Analysis</span>
                    </div>
                </div>

                <div class="experience-item">
                    <div class="experience-title">
                        Persona-based Chatbot "Haru"
                    </div>
                    <div class="experience-meta">
                        Linguistic Annotator @ <a href="https://www.sktelecom.com/index_en.html" target="_blank">SK Telecom</a> | Feb 2023 - Jun 2023
                    </div>
                    <div class="experience-desc">
                        <p>
                            I contributed to a persona-based chatbot by focusing on two linguistically central requirements for Korean dialogue:
                            (1) robustness to ambiguity in colloquial, non-canonical user inputs, and (2) sociolinguistic coverage across honorific/register variation.
                        </p>
                        <ul style="margin: 8px 0 0 18px;">
                            <li>Built a linguistically grounded ambiguity taxonomy (e.g., ellipsis, anaphora, spacing/noise, informal variants) to standardize how ambiguous inputs are handled.</li>
                            <li>Applied text normalization and preprocessing guided by the taxonomy to reduce interpretation noise and improve NLU robustness.</li>
                            <li>Led annotation efforts to ensure sociolinguistic coverage (honorific levels, informal slang, code-mixing) so the system behaves consistently across styles.</li>
                        </ul>
                        <p style="margin-top: 10px;">
                            <em>Key insight:</em> in Korean conversational products, performance depends not only on intent classification accuracy but also on pragmatic consistency under register shifts.
                        </p>
                    </div>
                    <div>
                        <span class="tech-tag">Ambiguity Taxonomy</span>
                        <span class="tech-tag">Text Normalization</span>
                        <span class="tech-tag">Sociolinguistic Variation</span>
                    </div>
                </div>
            </section>

            <section id="research">
                <h2>Research Experience</h2>

                <div class="experience-item">
                    <div class="experience-title">
                        Corpus Study for Sentiment Analysis & Chatbot NLU
                    </div>
                    <div class="experience-meta">
                        Undergraduate Research Intern @ <a href="http://dicora.kr/" target="_blank">DICORA Lab, HUFS</a> | Jan 2022 - Sep 2022
                    </div>
                    <div class="experience-desc">
                        <p>
                            At DICORA Lab, I worked on corpus-driven projects where the main goal was to turn raw text into usable linguistic resources.
                            I was involved in data construction, guideline iteration, and quality control across domains (finance and dialogue NLU).
                        </p>
                        <ul style="margin: 8px 0 0 18px;">
                            <li>Supported corpus collection and preprocessing pipelines, emphasizing consistent unit definitions (sentence, utterance) and annotation-ready formatting.</li>
                            <li>Assisted in annotation design and QA routines to improve label clarity and reduce ambiguity in training data.</li>
                            <li>Helped construct NLU datasets for chatbots with attention to semantic coverage and linguistic variation.</li>
                        </ul>
                    </div>
                    <div>
                        <span class="tech-tag">Corpus Linguistics</span>
                        <span class="tech-tag">Annotation Design</span>
                        <span class="tech-tag">NLU Data Curation</span>
                    </div>
                </div>
            </section>

            <section id="projects">
                <h2>Personal Project</h2>

                <div class="experience-item">
                    <div class="experience-title">
                        Linguistic Pattern Analysis for Financial Sentiment
                    </div>
                    <div class="experience-meta">
                        HUFS Linguistics Graduation Thesis Project | Sep 2022 - Dec 2022
                    </div>
                    <div class="experience-desc">
                        <p>
                            This thesis explored why sentiment in financial news cannot be captured by word lists alone.
                            I modeled sentiment compositionally by focusing on how attribute nouns (e.g., interest rates, costs) interact with directional predicates (rise/fall),
                            where polarity shifts depending on the semantics of the attribute.
                        </p>
                        <ul style="margin: 8px 0 0 18px;">
                            <li>Designed pattern-based rules grounded in lexical semantics and compositionality (e.g., “costs rise” vs “stock prices rise”).</li>
                            <li>Built a small, interpretable pipeline to extract attribute–predicate relations from financial text and analyzed common error patterns.</li>
                            <li>Reflected on limitations and extensions (e.g., industry metadata, context windows) for more robust interpretation.</li>
                        </ul>
                    </div>
                    <div>
                        <span class="tech-tag">Lexical Semantics</span>
                        <span class="tech-tag">Rule-Based NLP</span>
                        <span class="tech-tag">Sentiment Analysis</span>
                    </div>
                </div>
            </section>

        </main>
    </div>

</body>
</html>
